{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YEHhu06X2im"
      },
      "source": [
        "#Lab 6: Business Applications with Tabular Data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Classification"
      ],
      "metadata": {
        "id": "AYIrh73dtsfW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jFjFMqAX-yp"
      },
      "source": [
        "This data set contains information of cars purchased at the Auction.\n",
        "<br>\n",
        "We will use this file to predict the quality of buying decisions and visualize decision processes.\n",
        "<br>\n",
        "<br>\n",
        "VARIABLE DESCRIPTIONS:<br>\n",
        "Auction: Auction provider at which the  vehicle was purchased<br>\n",
        "Color: Vehicle Color<br>\n",
        "IsBadBuy: Identifies if the kicked vehicle was an avoidable purchase<br>\n",
        "MMRCurrentAuctionAveragePrice: Acquisition price for this vehicle in average condition as of current day<br>\n",
        "Size: The size category of the vehicle (Compact, SUV, etc.)<br>\n",
        "TopThreeAmericanName:Identifies if the manufacturer is one of the top three American manufacturers<br>\n",
        "VehBCost: Acquisition cost paid for the vehicle at time of purchase<br>\n",
        "VehicleAge: The Years elapsed since the manufacturer's year<br>\n",
        "VehOdo: The vehicles odometer reading<br>\n",
        "WarrantyCost: Warranty price (term=36month  and millage=36K)<br>\n",
        "WheelType: The vehicle wheel type description (Alloy, Covers)<br>\n",
        "<br>\n",
        "Target variable: **IsBadBuy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6UCBjrtG-g6"
      },
      "source": [
        "###1. Upload and clean data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-5vlFjOet49B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4db5s5prM1z8"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7vBYMeBG0ZE"
      },
      "source": [
        "# Read data\n",
        "carAuction = pd.read_csv(\"/content/drive/MyDrive/DL_data/carAuction.csv\")\n",
        "carAuction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiI3pabsNeRG"
      },
      "source": [
        "# Show the head rows of a data frame\n",
        "carAuction.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxp6-L5nNeRH"
      },
      "source": [
        "# Examine variable type\n",
        "carAuction.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tdv67wRNeRH"
      },
      "source": [
        "# Change categorical variables to \"category\"\n",
        "carAuction['Auction'] = carAuction['Auction'].astype('category')\n",
        "carAuction['Color'] = carAuction['Color'].astype('category')\n",
        "carAuction['IsBadBuy'] = carAuction['IsBadBuy'].astype('category')\n",
        "carAuction['Size'] = carAuction['Size'].astype('category')\n",
        "carAuction['TopThreeAmericanName'] = carAuction['TopThreeAmericanName'].astype('category')\n",
        "carAuction['WheelType'] = carAuction['WheelType'].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPWSMKGRpWAj"
      },
      "source": [
        "# Examine variable type\n",
        "carAuction.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3baHs-sknIT"
      },
      "source": [
        "###2. Partition the data set for Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGheFILukrMR"
      },
      "source": [
        "# Create dummy variables\n",
        "carAuction = pd.get_dummies(carAuction, columns=['Auction','Color','Size','TopThreeAmericanName','WheelType'],drop_first=True)\n",
        "carAuction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply standardization\n",
        "numeric_variables = carAuction[['MMRCurrentAuctionAveragePrice', 'VehBCost', 'VehicleAge', 'VehOdo', 'WarrantyCost']]\n",
        "scaler_s = StandardScaler().fit(numeric_variables)\n",
        "standard_variables = scaler_s.transform(numeric_variables)\n",
        "print(standard_variables)\n",
        "carAuction[['MMRCurrentAuctionAveragePrice', 'VehBCost', 'VehicleAge', 'VehOdo', 'WarrantyCost']] = standard_variables\n",
        "carAuction"
      ],
      "metadata": {
        "id": "cz46o-XwTAds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfxzlCPBnZ-4"
      },
      "source": [
        "# Partition the data\n",
        "target = carAuction['IsBadBuy']\n",
        "predictors = carAuction.drop(['IsBadBuy'], axis=1)\n",
        "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = 0)\n",
        "print(predictors_train.shape, predictors_test.shape, target_train.shape, target_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Y5U91BoVmf"
      },
      "source": [
        "# Examine the porportion of target variable for training data set\n",
        "print(target_train.value_counts(normalize= True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MasSsm8apCG-"
      },
      "source": [
        "# Examine the porportion of target variable for testing data set\n",
        "print(target_test.value_counts(normalize= True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt0XU6fmplzw"
      },
      "source": [
        "### 3. Neural network prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi8FlSIQpB_X"
      },
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  in_size, hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Linear(in_size, hidden_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size, hidden_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.network(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode label to numeric\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "new_label = label_encoder.fit_transform(target_train)\n",
        "new_label[:5], target_train[:5]"
      ],
      "metadata": {
        "id": "qDMjsm-q-sso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors from pandas dataframe\n",
        "predictors_train_tensor = torch.tensor(predictors_train.values)\n",
        "target_train_tensor = torch.tensor(label_encoder.transform(target_train.values))\n",
        "predictors_test_tensor = torch.tensor(predictors_test.values)\n",
        "target_test_tensor = torch.tensor(label_encoder.transform(target_test.values))\n",
        "\n",
        "# Create tensor dataset (set target variable to long int type)\n",
        "train_dataset = torch.utils.data.TensorDataset(predictors_train_tensor.float(), target_train_tensor.long())\n",
        "test_dataset = torch.utils.data.TensorDataset(predictors_test_tensor.float(), target_test_tensor.long())\n",
        "\n",
        "# Define training and testing data loader, and set batch size to 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "DkpOtnUv17_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 10 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "Ptpl8FHjAkpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n"
      ],
      "metadata": {
        "id": "gbACzwjIA1WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        " \n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1]))\n"
      ],
      "metadata": {
        "id": "mpZCNXPQEuBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n"
      ],
      "metadata": {
        "id": "taN61Cty7alc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVT5kkDQ1aen"
      },
      "source": [
        "Q1. On the testing set, how many bad buy cars are predicted as Not bad buy?<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahgldnbVzVuI"
      },
      "source": [
        "Q2. Does the decision tree model have better performance on majority (IsBadBuy = 'No') or minority class (IsBadBuy = 'Yes')? why? <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUIqtpm1cox_"
      },
      "source": [
        "Q3. Assume the following costs/benefits: \n",
        "*   Cost of buying a bad car: \\$2500\n",
        "*   Profit of purchasing a good car: \\$350\n",
        "*   Opportunity cost of a good car that is missed: \\$350\n",
        "<br>\n",
        "Based on the above costs / benefits, what is the total net benefit / cost of this neural network on testing data?<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k8bwGOXtl-1"
      },
      "source": [
        "## Part 2: Numeric Prediction\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX4rHIxjtl-3"
      },
      "source": [
        "In order for a health insurance company to make money, it needs to collect more\n",
        "in yearly premiums than it spends on medical care to its beneficiaries. As a result, insurers invest a great deal of time and money in developing models that accurately forecast medical expenses for the insured population.<br>\n",
        "<br>\n",
        "Medical expenses are difficult to estimate because the most costly conditions are rare and seemingly random. Still, some conditions are more prevalent for certain segments of the population. For instance, lung cancer is more likely among smokers than non-smokers, and heart disease may be more likely among the obese.<br>\n",
        "<br>\n",
        "The goal of this analysis is to use patient data to estimate the average medical\n",
        "care expenses for such population segments. These estimates can be used to create actuarial tables that set the price of yearly premiums higher or lower, \n",
        "depending on the expected treatment costs.<br>\n",
        "<br>\n",
        "The insurance data set has 1338 observations of 7 variables.\n",
        "<br>\n",
        "We will use this file to predict the medical expenses.\n",
        "<br>\n",
        "<br>\n",
        "VARIABLE DESCRIPTIONS:<br>\n",
        "age:\t      age in years<br>\n",
        "sex:\t      gender<br>\n",
        "bmi:\t      body mass index<br>\n",
        "children:\thow many children do they have?<br>\n",
        "smoker:\t  do they smoke?<br>\n",
        "region:\t  geographic region<br>\n",
        "expenses:\tyearly medical expenses<br>\n",
        "<br>\n",
        "Target variable: **expenses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xUY7mV8tl-3"
      },
      "source": [
        "### Upload and clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuoUv9latl-3"
      },
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_hJPEletl-3"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnBv5ogytl-4"
      },
      "source": [
        "# Read data\n",
        "insurance = pd.read_csv(\"/content/drive/MyDrive/DL_data/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjNbhdYLtl-4"
      },
      "source": [
        "# Show the head rows of a data frame\n",
        "insurance.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cEauvNxtl-4"
      },
      "source": [
        "# Examine variable type\n",
        "insurance.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F9GvPQFtl-4"
      },
      "source": [
        "# Change categorical variables to \"category\"\n",
        "insurance['sex'] = insurance['sex'].astype('category')\n",
        "insurance['smoker'] = insurance['smoker'].astype('category')\n",
        "insurance['region'] = insurance['region'].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZKoWREctl-4"
      },
      "source": [
        "# Examine variable type\n",
        "insurance.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzKcJa847XtX"
      },
      "source": [
        "# Data exploration: some examples\n",
        "# Histogram of insurance expenses\n",
        "snsplot = sns.histplot(x='expenses', data = insurance)\n",
        "snsplot.set_title(\"Histogram of expenses in the insurance data set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOeahm-d7eqy"
      },
      "source": [
        "# exploring relationships among all numeric variables: correlation matrix\n",
        "insurance.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzzGngi-tl-5"
      },
      "source": [
        "### Partition the data set for regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_HJEbCutl-5"
      },
      "source": [
        "# Create dummy variables\n",
        "insurance = pd.get_dummies(insurance, columns=['sex','smoker','region'], drop_first=True)\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply standardization\n",
        "numeric_variables = insurance[['age', 'bmi', 'children']]\n",
        "scaler_s = StandardScaler().fit(numeric_variables)\n",
        "standard_variables = scaler_s.transform(numeric_variables)\n",
        "print(standard_variables)\n",
        "insurance[['age', 'bmi', 'children']] = standard_variables"
      ],
      "metadata": {
        "id": "vNZu3j4vg9TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCGDY7astl-5"
      },
      "source": [
        "# Partition the data\n",
        "target = insurance['expenses']\n",
        "predictors = insurance.drop(['expenses'],axis=1)\n",
        "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.3, random_state=0)\n",
        "print(predictors_train.shape, predictors_test.shape, target_train.shape, target_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoY4Wl88tl-5"
      },
      "source": [
        "# Examine the distribution of target variable for training data set\n",
        "snsplot = sns.histplot(data = target_train)\n",
        "snsplot.set_title(\"Histogram of expenses in the training data set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teZ5RgTitl-5"
      },
      "source": [
        "# Examine the distribution of target variable for testing data set\n",
        "snsplot = sns.histplot(data = target_test)\n",
        "snsplot.set_title(\"Histogram of expenses in the testing data set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsFkb0uxP7T8"
      },
      "source": [
        "### 3. Neural network prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIDYc8UzP7T8"
      },
      "source": [
        "# Build a neural network on training data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor from pandas dataframe\n",
        "predictors_train_tensor = torch.tensor(predictors_train.values)\n",
        "target_train_tensor = torch.tensor(target_train.values)\n",
        "predictors_test_tensor = torch.tensor(predictors_test.values)\n",
        "target_test_tensor = torch.tensor(target_test.values)\n",
        "\n",
        "# Create tensor dataset (set target variable to float type)\n",
        "\n",
        "\n",
        "# Define training and testing data loader, and set batch size to 64\n"
      ],
      "metadata": {
        "id": "0bd0CRucP7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 100 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "4zOsEwmyP7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n"
      ],
      "metadata": {
        "id": "MnLPYClfP7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        " \n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  label_train = []\n",
        "  label_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          predict_train.append(outputs.tolist())\n",
        "          label_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          predict_test.append(outputs.tolist())\n",
        "          label_test.append(labels.tolist())\n",
        "  \n",
        "  MAE_train = mean_absolute_error(list(chain(*label_train)), list(chain(*predict_train)))\n",
        "  RMSE_train = mean_squared_error(list(chain(*label_train)), list(chain(*predict_train)), squared=False)\n",
        "\n",
        "  MAE_test = mean_absolute_error(list(chain(*label_test)), list(chain(*predict_test)))\n",
        "  RMSE_test = mean_squared_error(list(chain(*label_test)), list(chain(*predict_test)), squared=False)\n",
        "\n",
        "  print(\"Training MAE and RMSE:\", MAE_train, RMSE_train)\n",
        "  print()\n",
        "  print(\"testing MAE and RMSE:\", MAE_test, RMSE_test)"
      ],
      "metadata": {
        "id": "S8MHqAY5P7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n"
      ],
      "metadata": {
        "id": "RvzPofKmtow_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/DL_lab/Lab6_Business_Applications_with_Tabular_Data.ipynb\""
      ],
      "metadata": {
        "id": "4PCevx1-wkIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}