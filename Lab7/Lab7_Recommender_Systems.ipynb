{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YEHhu06X2im"
      },
      "source": [
        "#Lab7: Recommender Systems\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptb1cxRBXzNS"
      },
      "source": [
        "We will use the MovieLense 1M ratings data (downloaded from http://www.grouplens.org/), which contains around 1,000,000 ratings (1-5) from 6,000 users on 4,000 movies.<br> \n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**USERS FILE DESCRIPTION** <br>\n",
        "\n",
        "User information is in the file \"users.dat\".<br>\n",
        "\n",
        "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
        "- Age is chosen from the following ranges:\n",
        "\n",
        "\t*  1:  \"Under 18\"\n",
        "\t* 18:  \"18-24\"\n",
        "\t* 25:  \"25-34\"\n",
        "\t* 35:  \"35-44\"\n",
        "\t* 45:  \"45-49\"\n",
        "\t* 50:  \"50-55\"\n",
        "\t* 56:  \"56+\"\n",
        "\n",
        "- Occupation is chosen from the following choices:\n",
        "\n",
        "\t*  0:  \"other\" or not specified\n",
        "\t*  1:  \"academic/educator\"\n",
        "\t*  2:  \"artist\"\n",
        "\t*  3:  \"clerical/admin\"\n",
        "\t*  4:  \"college/grad student\"\n",
        "\t*  5:  \"customer service\"\n",
        "\t*  6:  \"doctor/health care\"\n",
        "\t*  7:  \"executive/managerial\"\n",
        "\t*  8:  \"farmer\"\n",
        "\t*  9:  \"homemaker\"\n",
        "\t* 10:  \"K-12 student\"\n",
        "\t* 11:  \"lawyer\"\n",
        "\t* 12:  \"programmer\"\n",
        "\t* 13:  \"retired\"\n",
        "\t* 14:  \"sales/marketing\"\n",
        "\t* 15:  \"scientist\"\n",
        "\t* 16:  \"self-employed\"\n",
        "\t* 17:  \"technician/engineer\"\n",
        "\t* 18:  \"tradesman/craftsman\"\n",
        "\t* 19:  \"unemployed\"\n",
        "\t* 20:  \"writer\"\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**MOVIES FILE DESCRIPTION** <br>\n",
        "\n",
        "Movie information is in the file \"movies.dat\" \n",
        "\n",
        "- Titles are identical to titles provided by the IMDB (including\n",
        "year of release)\n",
        "- Genres are pipe-separated and are selected from the following genres:\n",
        "\t* Action\n",
        "\t* Adventure\n",
        "\t* Animation\n",
        "\t* Children's\n",
        "\t* Comedy\n",
        "\t* Crime\n",
        "\t* Documentary\n",
        "\t* Drama\n",
        "\t* Fantasy\n",
        "\t* Film-Noir\n",
        "\t* Horror\n",
        "\t* Musical\n",
        "\t* Mystery\n",
        "\t* Romance\n",
        "\t* Sci-Fi\n",
        "\t* Thriller\n",
        "\t* War\n",
        "\t* Western\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**RATINGS FILE DESCRIPTION** <br>\n",
        "\n",
        "All ratings are contained in the file \"ratings.dat\" \n",
        "- UserIDs range between 1 and 6040 \n",
        "- MovieIDs range between 1 and 3952\n",
        "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
        "- Unix Timestamp is represented in seconds since the epoch (the number of seconds that have elapsed since January 1, 1970)\n",
        "- Each user has at least 20 ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqVXzbWOAyl"
      },
      "source": [
        "## 1: Upload and clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN5GlqkdOAyl"
      },
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB0z7Bl3OAym"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from itertools import chain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TreFR3tOOAym"
      },
      "source": [
        "# Read user data\n",
        "u_columns = ['user_id', 'gender', 'age', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('/content/drive/MyDrive/DL_data/users.dat', sep='::', names=u_columns, engine='python')\n",
        "users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU0EyniGh3JS"
      },
      "source": [
        "# Read movie data\n",
        "m_columns = ['movie_id', 'title', 'genre']\n",
        "movies = pd.read_csv('/content/drive/MyDrive/DL_data/movies.dat', sep='::', names=m_columns, encoding='latin-1', engine='python')\n",
        "movies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZN0y1erh5c8"
      },
      "source": [
        "# Read rating data\n",
        "r_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/DL_data/ratings.dat', sep = '::', names=r_columns, engine='python')\n",
        "ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cKBWBheiScy"
      },
      "source": [
        "# create one merged DataFrame\n",
        "movie_ratings = pd.merge(movies, ratings)\n",
        "MovieLense = pd.merge(movie_ratings, users)\n",
        "MovieLense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__UY8gZSOAym"
      },
      "source": [
        "# Show the head of data frame\n",
        "MovieLense.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: Data Preprocessing"
      ],
      "metadata": {
        "id": "fOP5IuS5IlRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode movie_id and user_id\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "ratings['movie_id'] = label_encoder.fit_transform(ratings['movie_id'])\n",
        "ratings['user_id'] = label_encoder.fit_transform(ratings['user_id'])\n",
        "ratings"
      ],
      "metadata": {
        "id": "mj27KbSuMsOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort data based on 'user_id' and 'timestamp'\n",
        "ratings = ratings.sort_values(by=['user_id', 'timestamp'])\n",
        "ratings"
      ],
      "metadata": {
        "id": "vfEh19kYfYxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Partition the data\n",
        "test_data = ratings.drop_duplicates(subset=[\"user_id\"], keep='last')\n",
        "index_df = ratings.index.isin(test_data.index)\n",
        "train_data = ratings.iloc[~index_df]\n",
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "id": "NJqU_RwHfTxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the timestamp column\n",
        "train_data = train_data[['user_id', 'movie_id', 'rating']]\n",
        "test_data = test_data[['user_id', 'movie_id', 'rating']]\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "metadata": {
        "id": "5TId9_42n-C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_hfK-RpOAyn"
      },
      "source": [
        "## 3: Explore the MovieLense data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of users\n",
        "user_num = len(ratings['user_id'].unique())\n",
        "user_num"
      ],
      "metadata": {
        "id": "Xkggw_qt3dO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of movies\n",
        "movie_num = len(ratings['movie_id'].unique())\n",
        "movie_num"
      ],
      "metadata": {
        "id": "EdaMc5TS4IoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE0PPBSMOAyn"
      },
      "source": [
        "# Rating information\n",
        "ratings['rating'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN15gHk9kd2n"
      },
      "source": [
        "# Rating distribution\n",
        "sns.countplot(x='rating', data=ratings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urvcg1LpW4x_"
      },
      "source": [
        "## 4: Collaborative Filtering Recommender Systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bboolXRhwhKL"
      },
      "source": [
        "# Create user-item matrix for training and testing data\n",
        "train_matrix = np.zeros([user_num, movie_num])\n",
        "for line in train_data.itertuples():\n",
        "  train_matrix[line.user_id, line.movie_id] = line.rating\n",
        "\n",
        "test_matrix = np.zeros([user_num, movie_num])\n",
        "for line in test_data.itertuples():\n",
        "  test_matrix[line.user_id, line.movie_id] = line.rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M-D29Zxy6Mv"
      },
      "source": [
        "# calculate the average rating for each user\n",
        "average_user_rating = np.true_divide(train_matrix.sum(1),(train_matrix!=0).sum(1))\n",
        "\n",
        "# create a train_matrix_sp represents users' preferences on different movies\n",
        "train_matrix_sp = csr_matrix(train_matrix, dtype=np.float64)\n",
        "nz = train_matrix_sp.nonzero()\n",
        "train_matrix_sp[nz] -= average_user_rating[nz[0]]\n",
        "train_matrix_sp = train_matrix_sp.toarray()\n",
        "\n",
        "# calculate the user and movie similarity\n",
        "user_similarity = pairwise_distances(train_matrix_sp)\n",
        "movie_similarity = pairwise_distances(train_matrix_sp.T)\n",
        "np.fill_diagonal(user_similarity, 0)\n",
        "np.fill_diagonal(movie_similarity, 0)\n",
        "print(user_similarity)\n",
        "print(movie_similarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubrWDbDp0aA2"
      },
      "source": [
        "# Create a collaborative filtering algorithm\n",
        "zero_index = np.zeros(train_matrix_sp.shape)\n",
        "zero_index[nz] = 1\n",
        "def collaborative_filtering (type = 'user'):\n",
        "  if type == 'user':\n",
        "    pre_rating = average_user_rating[:, np.newaxis] + np.dot(user_similarity, train_matrix_sp)/np.dot(user_similarity, zero_index)\n",
        "  if type == 'item':\n",
        "    pre_rating = (np.dot(movie_similarity, train_matrix.T)/np.dot(movie_similarity, zero_index.T)).T\n",
        "  return pre_rating\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIUd8mf3EaGL"
      },
      "source": [
        "# make predictions\n",
        "user_prediction = collaborative_filtering(type='user')\n",
        "item_prediction = collaborative_filtering(type='item')\n",
        "user_prediction = np.nan_to_num(user_prediction, nan=4)\n",
        "item_prediction = np.nan_to_num(item_prediction, nan=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA0c_WBLXlUz"
      },
      "source": [
        "# Examine the evaluation results of user-based collaborative filtering on testing data: MAE and RMSE\n",
        "MAE = mean_absolute_error(test_matrix[test_matrix!=0], user_prediction[test_matrix!=0])\n",
        "RMSE = mean_squared_error(test_matrix[test_matrix!=0], user_prediction[test_matrix!=0], squared=False)\n",
        "print(\"MAE:\", MAE)\n",
        "print(\"RMSE:\", RMSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PDsrgcaSRFH"
      },
      "source": [
        "# Examine the evaluation results of item-based collaborative filtering on testing data: MAE and RMSE\n",
        "MAE = mean_absolute_error(test_matrix[test_matrix!=0], item_prediction[test_matrix!=0])\n",
        "RMSE = mean_squared_error(test_matrix[test_matrix!=0], item_prediction[test_matrix!=0], squared=False)\n",
        "print(\"MAE:\", MAE)\n",
        "print(\"RMSE:\", RMSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6OmLX_vf6JN"
      },
      "source": [
        "Q1. Which recommender system has better performance, user-based or item-based, and why? <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Neural Collaborative Filtering"
      ],
      "metadata": {
        "id": "cw0OsJomolw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  emb_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, out_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_emb = nn.Embedding(user_num, emb_size)\n",
        "        self.item_emb = nn.Embedding(movie_num, emb_size)\n",
        "        \n",
        "        self.network = nn.Sequential(\n",
        "          nn.Linear(emb_size*2, hidden_size1),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size1, hidden_size2),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size2, hidden_size3),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size3, hidden_size4),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size4, out_size))\n",
        "\n",
        "    def forward(self, u_id, v_id):\n",
        "        u = self.user_emb(u_id)\n",
        "        v = self.item_emb(v_id)\n",
        "        c = torch.cat([u,v], dim = 1)\n",
        "        out = self.network(c)\n",
        "        out_sig = torch.sigmoid(out) * 5.0\n",
        "        return out_sig.squeeze()"
      ],
      "metadata": {
        "id": "hyaK7qIpsipU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor from pandas dataframe\n",
        "\n",
        "\n",
        "# Create tensor dataset\n",
        "\n",
        "\n",
        "# Define training and testing data loader, and set batch size to 512\n"
      ],
      "metadata": {
        "id": "PrwfeIYzyEB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for user_input, movie_input, labels in train_loader: # (user_input, movie_input, labels) are from (train_user_tensor, train_movie_tensor, train_rating_tensor) in train_dataset\n",
        "                                                             # (user_input, movie_input, labels) are the inputs for each batch\n",
        "            outputs = model(user_input, movie_input) # (user_input, movie_input) correspond to the u_id, v_id, which are the inputs of the forward(self, u_id, v_id) function\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "Hn3svTz4iq1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n"
      ],
      "metadata": {
        "id": "IXaHX8twjNe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        " \n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  label_train = []\n",
        "  label_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for user_input, movie_input, labels in train_loader: # (user_input, movie_input, labels) are from (train_user_tensor, train_movie_tensor, train_rating_tensor) in train_dataset\n",
        "                                                           # (user_input, movie_input, labels) are the inputs for each batch\n",
        "          outputs = model(user_input, movie_input)         # (user_input, movie_input) correspond to the u_id, v_id, which are the inputs of the forward(self, u_id, v_id) function\n",
        "          predict_train.append(outputs.tolist())\n",
        "          label_train.append(labels.tolist())\n",
        "\n",
        "      for user_input, movie_input, labels in test_loader: # (user_input, movie_input, labels) are from (test_user_tensor, test_movie_tensor, test_rating_tensor) in test_dataset\n",
        "                                                          # (user_input, movie_input, labels) are the inputs for each batch\n",
        "          outputs = model(user_input, movie_input)        # (user_input, movie_input) correspond to the u_id, v_id, which are the inputs of the forward(self, u_id, v_id) function\n",
        "          predict_test.append(outputs.tolist())\n",
        "          label_test.append(labels.tolist())\n",
        "  \n",
        "  MAE_train = mean_absolute_error(list(chain(*label_train)), list(chain(*predict_train)))\n",
        "  RMSE_train = mean_squared_error(list(chain(*label_train)), list(chain(*predict_train)), squared=False)\n",
        "\n",
        "  MAE_test = mean_absolute_error(list(chain(*label_test)), list(chain(*predict_test)))\n",
        "  RMSE_test = mean_squared_error(list(chain(*label_test)), list(chain(*predict_test)), squared=False)\n",
        "\n",
        "  print(\"Training MAE and RMSE:\", MAE_train, RMSE_train)\n",
        "  print()\n",
        "  print(\"Testing MAE and RMSE:\", MAE_test, RMSE_test)"
      ],
      "metadata": {
        "id": "Lfl-AFprjknv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n"
      ],
      "metadata": {
        "id": "RvzPofKmtow_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/DL_lab/Lab7:Recommender_Systems.ipynb\""
      ],
      "metadata": {
        "id": "4PCevx1-wkIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}