{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Ewpcs3Nv9t"
      },
      "source": [
        "#IS 675 Lab 9: Learning from Images with Convolutions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Butterfly Classification <br>\n",
        "Train, Test data set for 10 butterfly species. All images are 224 X 224 X 3 in jpg format."
      ],
      "metadata": {
        "id": "XOjk_ZR__4TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "U2-gwKCbEvSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "AafvpfG-PXbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline\n",
        "Butterfly_trans = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor() # ToTensor() converts images to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "])"
      ],
      "metadata": {
        "id": "GHfO4K8xLs2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/DL_data/train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/DL_data/test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "4UMwBT2K8RCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_butterfly10.classes)"
      ],
      "metadata": {
        "id": "Ej7VX-iy9VzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the sizes of training and test data\n",
        "print(len(train_butterfly10), len(test_butterfly10))"
      ],
      "metadata": {
        "id": "MMbLKPavMReE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40W2zkgVMReE"
      },
      "outputs": [],
      "source": [
        "class_names = ['AN 88','BLUE MORPHO','COMMON WOOD-NYMPH','MONARCH','PEACOCK','PIPEVINE SWALLOW','ULYSES','VICEROY','YELLOW SWALLOW TAIL','ZEBRA LONG WING']\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "num_classes = 10\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    ax.set_title(class_names[i])\n",
        "    img = next(img for img, label in test_butterfly10 if label == i)\n",
        "    if i == 3:\n",
        "      example_img = img\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the tensor of a zebra long wing image\n",
        "print(img.shape)\n",
        "print(img)"
      ],
      "metadata": {
        "id": "ylMyRHQyMReE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convolutions"
      ],
      "metadata": {
        "id": "1bPLaAg1Y_iA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2lXrVU57TCa"
      },
      "outputs": [],
      "source": [
        "#nn.Conv2d are the number of input features (or channels, since weâ€™re dealing with multichannel images: that is, more than one value per pixel), the number of output features, and the size of the kernel.\n",
        "conv = nn.Conv2d(3, 16, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4Ca3WUa7TCa"
      },
      "outputs": [],
      "source": [
        "conv.weight.shape, conv.bias.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = conv(example_img)\n",
        "example_img.shape, output.shape"
      ],
      "metadata": {
        "id": "ZwSkTEd-MeMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_DCwX4SXCFH"
      },
      "outputs": [],
      "source": [
        "# Maintain the same image size with padding\n",
        "conv = nn.Conv2d(3, 16, kernel_size=5, padding=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pokZKINwXCFH"
      },
      "outputs": [],
      "source": [
        "output = conv(example_img)\n",
        "\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detecting features with convolutions "
      ],
      "metadata": {
        "id": "A51kcaezXRO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(example_img[0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "obgwJCeCMeHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_IftXnC1dVW"
      },
      "outputs": [],
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0]])\n",
        "    conv.bias.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GliBWeY1dVX"
      },
      "outputs": [],
      "source": [
        "output = conv(example_img)\n",
        "plt.imshow(output[0].detach(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpbaAvQ6XRO8"
      },
      "outputs": [],
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    conv.weight[:] = torch.tensor([[-1.0, -1.0, -1.0],\n",
        "                                   [0.0, 0.0, 0.0],\n",
        "                                   [1.0, 1.0, 1.0]])\n",
        "    conv.bias.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAUmRdPvXRO8"
      },
      "outputs": [],
      "source": [
        "output = conv(example_img)\n",
        "plt.imshow(output[0].detach(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Looking Further with Depth and Pooling"
      ],
      "metadata": {
        "id": "5vYWJQY9XpD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCU4lrJWXpD1"
      },
      "outputs": [],
      "source": [
        "# Downsample our image\n",
        "pool = nn.MaxPool2d(4)\n",
        "output = pool(img)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model training and evaluation"
      ],
      "metadata": {
        "id": "kRZeP-9Caiwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the mean and std of images in the training data\n",
        "imgs = torch.stack([img_t for img_t, label in train_butterfly10], dim=3)\n",
        "print(imgs.view(3, -1).mean(dim=1), imgs.view(3, -1).std(dim=1))"
      ],
      "metadata": {
        "id": "IKZYjNQ6MReE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline to include normalization\n",
        "Butterfly_trans = transforms.Compose([transforms.Resize((224, 224)), # composes several transforms together\n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.4621, 0.4528, 0.3400],std=[0.2884, 0.2767, 0.2862])\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "1jUzgvzrMReE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/DL_data/train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/DL_data/test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "LoxYkb76MReE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and testing data loader, and set batch size to 128\n",
        "train_loader_butterfly10 = torch.utils.data.DataLoader(train_butterfly10, batch_size=128, shuffle=True)\n",
        "test_loader_butterfly10 = torch.utils.data.DataLoader(test_butterfly10, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "xxo3lYcXMReF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICH553XxXpD1"
      },
      "outputs": [],
      "source": [
        "# Build a neural network on training data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "9xjfY0HtMReF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n"
      ],
      "metadata": {
        "id": "2kvm5l0ZMReF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        " \n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n"
      ],
      "metadata": {
        "id": "f8pduIMTMReF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n"
      ],
      "metadata": {
        "id": "5nQEZpATMReF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training on the GPU"
      ],
      "metadata": {
        "id": "oWNRPT8_bgX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change the Notebook Settings in Colab**: Edit-> Notebook Settings -> GPU"
      ],
      "metadata": {
        "id": "5aQ1XZ22bgX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "76nF80M9LqNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT3iqhOMbgX5"
      },
      "outputs": [],
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "TXQ-z5KKLqNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline to include normalization\n",
        "Butterfly_trans = transforms.Compose([transforms.Resize((224, 224)), # composes several transforms together\n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.4621, 0.4528, 0.3400],std=[0.2884, 0.2767, 0.2862])\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "LouifMmtLqNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/DL_data/train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/DL_data/test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "Hwu4hByULqNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and testing data loader, and set batch size to 128\n",
        "train_loader_butterfly10 = torch.utils.data.DataLoader(train_butterfly10, batch_size=128, shuffle=True)\n",
        "test_loader_butterfly10 = torch.utils.data.DataLoader(test_butterfly10, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "R6CXMOGgLzZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzQBVrONL8lM"
      },
      "outputs": [],
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Conv2d(3, 8, kernel_size=5, padding=2), # 8 x 224 x 224 image\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(4), # 8 x 56 x 56 image\n",
        "          nn.Conv2d(8, 4, kernel_size=3, padding=1), # 4 x 56 x 56 image\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(4), # 4 x 14 x 14 image\n",
        "          nn.Flatten(), # (-1, 4 * 14 * 14)\n",
        "          nn.Linear(4 * 14 * 14, hidden_size), # (-1, 32)\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.network(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            # These two lines that move inputs and labels to the device we are training on are the only difference from our previous version.\n",
        "            inputs = inputs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "AH20-FjOKyJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "# Model training\n",
        "torch.manual_seed(0)\n",
        "model = neural_network(32, 10).to(device=device) # Move our model (all parameters) to the GPU\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(n_epochs = 20, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_loader_butterfly10)"
      ],
      "metadata": {
        "id": "qw5nmo3_KyJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        " \n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          # These two lines that move inputs and labels to the device we are training on are the only difference from our previous version.\n",
        "          inputs = inputs.to(device=device)\n",
        "          labels = labels.to(device=device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          # These two lines that move inputs and labels to the device we are training on are the only difference from our previous version.\n",
        "          inputs = inputs.to(device=device)\n",
        "          labels = labels.to(device=device)\n",
        "          \n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n"
      ],
      "metadata": {
        "id": "days02mkK7wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n",
        "test(model, train_loader_butterfly10, test_loader_butterfly10)"
      ],
      "metadata": {
        "id": "QC6v2evbK7wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a html file\n",
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/DL_lab/Lab9:Learning_from_Images_with_Convolutions.ipynb\""
      ],
      "metadata": {
        "id": "5pITQiF7G_9x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}