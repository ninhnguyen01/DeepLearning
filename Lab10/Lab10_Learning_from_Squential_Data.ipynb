{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Ewpcs3Nv9t"
      },
      "source": [
        "#Lab 10: Deep Learning For Sequential Data\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future total sales of pizza<br>\n",
        "In this lab, we will predict the future total sales of pizza based on the sequential transactions by using LSTM.<br><br>\n",
        "\n",
        "This pizza sales dataset make up 12 relevant features:<br>\n",
        "\n",
        "order_id: Unique identifier for each order placed by a table<br>\n",
        "order_details_id: Unique identifier for each pizza placed within each order (pizzas of the same type and size are kept in the same row, and the quantity increases)<br>\n",
        "pizza_id: Unique key identifier that ties the pizza ordered to its details, like size and price<br>\n",
        "quantity: Quantity ordered for each pizza of the same type and size\n",
        "order_date: Date the order was placed (entered into the system prior to cooking & serving)<br>\n",
        "order_time: Time the order was placed (entered into the system prior to cooking & serving)<br>\n",
        "unit_price: Price of the pizza in USD<br>\n",
        "total_price: unit_price * quantity<br>\n",
        "pizza_size: Size of the pizza (Small, Medium, Large, X Large, or XX Large)<br>\n",
        "pizza_type: Unique key identifier that ties the pizza ordered to its details, like size and price<br>\n",
        "pizza_ingredients: ingredients used in the pizza as shown in the menu (they all include Mozzarella Cheese, even if not specified; and they all include Tomato Sauce, unless another sauce is specified)<br>\n",
        "pizza_name: Name of the pizza as shown in the menu<br>"
      ],
      "metadata": {
        "id": "XOjk_ZR__4TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "U2-gwKCbEvSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "AafvpfG-PXbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6UCBjrtG-g6"
      },
      "source": [
        "###1. Upload and clean data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "PizzaSales = pd.read_csv(\"/content/drive/MyDrive/DL_data/PizzaSales.csv\")\n",
        "PizzaSales"
      ],
      "metadata": {
        "id": "4cH0_H_02RCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the head rows of a data frame\n",
        "PizzaSales.head()"
      ],
      "metadata": {
        "id": "jEbNe7QF3E4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine variable type\n",
        "PizzaSales.dtypes"
      ],
      "metadata": {
        "id": "t0A52i_H3E1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine data size\n",
        "PizzaSales.shape"
      ],
      "metadata": {
        "id": "DwAvybav3Ew4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3baHs-sknIT"
      },
      "source": [
        "###2. Simple data exploration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert order_date column to datetime\n",
        "PizzaSales['order_date'] = pd.to_datetime(PizzaSales['order_date'])"
      ],
      "metadata": {
        "id": "LGbDwsQxqPBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exam the number of pizza sold by month\n",
        "PizzaSales['order_month'] =pd.DatetimeIndex(PizzaSales['order_date']).month\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==1), 'order_month'] = 'January'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==2), 'order_month'] = 'February'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==3), 'order_month'] = 'March'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==4), 'order_month'] = 'April'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==5), 'order_month'] = 'May'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==6), 'order_month'] = 'June'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==7), 'order_month'] = 'July'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==8), 'order_month'] = 'August'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==9), 'order_month'] = 'September'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==10), 'order_month'] = 'October'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==11), 'order_month'] = 'November'\n",
        "PizzaSales.loc[(PizzaSales['order_month'] ==12), 'order_month'] = 'December'\n",
        "PizzaSales['order_month'].value_counts()"
      ],
      "metadata": {
        "id": "CaW0w8E7RRoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exam the number of pizza sold by day\n",
        "PizzaSales[\"Dayofweek\"] = PizzaSales['order_date'].dt.day_name()\n",
        "PizzaSales[\"Dayofweek\"].value_counts()"
      ],
      "metadata": {
        "id": "Oxx9QKFUMfi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the number of pizza sold by hour\n",
        "PizzaSales[['Hour','Minute', 'Second']]= PizzaSales['order_time'].str.split(\":\",expand=True)\n",
        "PizzaSales[\"Hour\"].value_counts()"
      ],
      "metadata": {
        "id": "Uje8OraZKZ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the number of pizza sold by pizza id\n",
        "PizzaSales[\"pizza_id\"].value_counts()"
      ],
      "metadata": {
        "id": "ylinLqmBKZ5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the number of pizza sold by pizza size\n",
        "PizzaSales[\"pizza_size\"].value_counts()"
      ],
      "metadata": {
        "id": "26oop9HFfRWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PizzaSales['order_id'].max()"
      ],
      "metadata": {
        "id": "XLQU6ermhTTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the average order value\n",
        "PizzaSales['total_price'].agg('sum')/PizzaSales['order_id'].max()"
      ],
      "metadata": {
        "id": "11LuRC3JKZ1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXJOTzwgiEFp"
      },
      "source": [
        "###3. Partition the data set for pizza sales prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Organize sales by date\n",
        "sales_by_date = PizzaSales.groupby(['order_date']).sum()\n",
        "sales_by_date[\"Dayofweek\"] = sales_by_date.index.day_name()\n",
        "sales_by_date = sales_by_date[['quantity','total_price','Dayofweek']]\n",
        "sales_by_date"
      ],
      "metadata": {
        "id": "5kJVYWPaQMXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy variables\n",
        "sales_by_date = pd.get_dummies(sales_by_date, columns=['Dayofweek'],drop_first=True)\n",
        "sales_by_date"
      ],
      "metadata": {
        "id": "M8Cphsejs9z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the total sales\n"
      ],
      "metadata": {
        "id": "1BdKBcwqe22C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply standardization\n",
        "numeric_variables = sales_by_date[['quantity', 'total_price']]\n",
        "scaler_s = StandardScaler().fit(numeric_variables)\n",
        "standard_variables = scaler_s.transform(numeric_variables)\n",
        "sales_by_date[['quantity', 'total_price']] = standard_variables"
      ],
      "metadata": {
        "id": "Z7ldh848fttk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences\n"
      ],
      "metadata": {
        "id": "8z8nsjybs9v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Partition the data\n",
        "target = seq_data['total_sales']\n",
        "predictors = seq_data.drop(['total_sales'], axis=1)\n",
        "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.3, random_state = 0)\n",
        "print(predictors_train.shape, predictors_test.shape, target_train.shape, target_test.shape)"
      ],
      "metadata": {
        "id": "U2htA27gs9o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the distribution of target variable for training data set\n",
        "snsplot = sns.histplot(data = target_train)\n",
        "snsplot.set_title(\"Histogram of total_sales in the training data set\")"
      ],
      "metadata": {
        "id": "vYxAS58F3EkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the distribution of target variable for testing data set\n",
        "snsplot = sns.histplot(data = target_test)\n",
        "snsplot.set_title(\"Histogram of total_sales in the testing data set\")"
      ],
      "metadata": {
        "id": "Qlqy4eFp6-Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsFkb0uxP7T8"
      },
      "source": [
        "### 4. Neural network prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIDYc8UzP7T8"
      },
      "source": [
        "# Build a neural network on training data\n",
        "class extract_tensor(nn.Module):\n",
        "    def forward(self,x):\n",
        "        tensor, _ = x\n",
        "        return tensor[:, -1, :]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor from pandas dataframe\n",
        "predictors_train_tensor = torch.tensor(predictors_train.values).view(248, 3, 8) # reshape the tensor to 248 sequences; each sequence has length = 3 and input size = 8 (will be used to predict the next day's sale based on the sales and orders of the past three days)\n",
        "target_train_tensor = torch.tensor(target_train.values)\n",
        "predictors_test_tensor = torch.tensor(predictors_test.values).view(107, 3, 8)\n",
        "target_test_tensor = torch.tensor(target_test.values)\n",
        "\n",
        "# Create tensor dataset (set target variable to float type)\n",
        "train_dataset = torch.utils.data.TensorDataset(predictors_train_tensor.float(), target_train_tensor.float())\n",
        "test_dataset = torch.utils.data.TensorDataset(predictors_test_tensor.float(), target_test_tensor.float())\n",
        "\n",
        "# Define training and testing data loader, and set batch size to 16\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "0bd0CRucP7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 50 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "4zOsEwmyP7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n"
      ],
      "metadata": {
        "id": "MnLPYClfP7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        " \n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  label_train = []\n",
        "  label_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          predict_train.append(outputs.tolist())\n",
        "          label_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          predict_test.append(outputs.tolist())\n",
        "          label_test.append(labels.tolist())\n",
        "  \n",
        "  MAE_train = mean_absolute_error(list(chain(*label_train)), list(chain(*predict_train)))\n",
        "  RMSE_train = mean_squared_error(list(chain(*label_train)), list(chain(*predict_train)), squared=False)\n",
        "\n",
        "  MAE_test = mean_absolute_error(list(chain(*label_test)), list(chain(*predict_test)))\n",
        "  RMSE_test = mean_squared_error(list(chain(*label_test)), list(chain(*predict_test)), squared=False)\n",
        "\n",
        "  print(\"Training MAE and RMSE:\", MAE_train, RMSE_train)\n",
        "  print()\n",
        "  print(\"testing MAE and RMSE:\", MAE_test, RMSE_test)"
      ],
      "metadata": {
        "id": "S8MHqAY5P7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n"
      ],
      "metadata": {
        "id": "RvzPofKmtow_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/DL_lab/Lab10:Learning_from_Squential_Data.ipynb\""
      ],
      "metadata": {
        "id": "4PCevx1-wkIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}