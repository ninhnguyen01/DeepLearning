<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head></head><body>





















    
    
    
    

  <div class="border-box-sizing">
    <div class="container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Lab 3: Pretrained Networks<a rel="noopener" class="anchor-link" href="#Lab-3:-Pretrained-Networks">&#182;</a></h1><hr/>
<p>In this lab, we will explore two popular pretrained models: a model that can label an image according to its content, and another that can fabricate a new image from a real image (image-to-image translation).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Part 1: A pretrained network that recognizes the subject of an image<br/></h2>
<p>We’ll run a state-of-the-art deep neural network that was pretrained on an object-recognition task.<br/> 
<br/>
The pretrained network we’ll explore here was trained on a subset of the ImageNet dataset (<a rel="noopener" href="http://imagenet.stanford.edu">http://imagenet.stanford.edu</a>).<br/>
ImageNet is a very large dataset of over 14 million images maintained by Stanford University. All of the images are labeled with a hierarchy of nouns that come from the WordNet dataset (<a rel="noopener" href="http://wordnet.princeton.edu">http://wordnet.princeton.edu</a>).<br/>
<br/></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Mounting Google Drive</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Import libraries</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Directory function to examine the models</span>
<span class="nb">dir</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[&#39;AlexNet&#39;,
 &#39;AlexNet_Weights&#39;,
 &#39;ConvNeXt&#39;,
 &#39;ConvNeXt_Base_Weights&#39;,
 &#39;ConvNeXt_Large_Weights&#39;,
 &#39;ConvNeXt_Small_Weights&#39;,
 &#39;ConvNeXt_Tiny_Weights&#39;,
 &#39;DenseNet&#39;,
 &#39;DenseNet121_Weights&#39;,
 &#39;DenseNet161_Weights&#39;,
 &#39;DenseNet169_Weights&#39;,
 &#39;DenseNet201_Weights&#39;,
 &#39;EfficientNet&#39;,
 &#39;EfficientNet_B0_Weights&#39;,
 &#39;EfficientNet_B1_Weights&#39;,
 &#39;EfficientNet_B2_Weights&#39;,
 &#39;EfficientNet_B3_Weights&#39;,
 &#39;EfficientNet_B4_Weights&#39;,
 &#39;EfficientNet_B5_Weights&#39;,
 &#39;EfficientNet_B6_Weights&#39;,
 &#39;EfficientNet_B7_Weights&#39;,
 &#39;EfficientNet_V2_L_Weights&#39;,
 &#39;EfficientNet_V2_M_Weights&#39;,
 &#39;EfficientNet_V2_S_Weights&#39;,
 &#39;GoogLeNet&#39;,
 &#39;GoogLeNetOutputs&#39;,
 &#39;GoogLeNet_Weights&#39;,
 &#39;Inception3&#39;,
 &#39;InceptionOutputs&#39;,
 &#39;Inception_V3_Weights&#39;,
 &#39;MNASNet&#39;,
 &#39;MNASNet0_5_Weights&#39;,
 &#39;MNASNet0_75_Weights&#39;,
 &#39;MNASNet1_0_Weights&#39;,
 &#39;MNASNet1_3_Weights&#39;,
 &#39;MobileNetV2&#39;,
 &#39;MobileNetV3&#39;,
 &#39;MobileNet_V2_Weights&#39;,
 &#39;MobileNet_V3_Large_Weights&#39;,
 &#39;MobileNet_V3_Small_Weights&#39;,
 &#39;RegNet&#39;,
 &#39;RegNet_X_16GF_Weights&#39;,
 &#39;RegNet_X_1_6GF_Weights&#39;,
 &#39;RegNet_X_32GF_Weights&#39;,
 &#39;RegNet_X_3_2GF_Weights&#39;,
 &#39;RegNet_X_400MF_Weights&#39;,
 &#39;RegNet_X_800MF_Weights&#39;,
 &#39;RegNet_X_8GF_Weights&#39;,
 &#39;RegNet_Y_128GF_Weights&#39;,
 &#39;RegNet_Y_16GF_Weights&#39;,
 &#39;RegNet_Y_1_6GF_Weights&#39;,
 &#39;RegNet_Y_32GF_Weights&#39;,
 &#39;RegNet_Y_3_2GF_Weights&#39;,
 &#39;RegNet_Y_400MF_Weights&#39;,
 &#39;RegNet_Y_800MF_Weights&#39;,
 &#39;RegNet_Y_8GF_Weights&#39;,
 &#39;ResNeXt101_32X8D_Weights&#39;,
 &#39;ResNeXt101_64X4D_Weights&#39;,
 &#39;ResNeXt50_32X4D_Weights&#39;,
 &#39;ResNet&#39;,
 &#39;ResNet101_Weights&#39;,
 &#39;ResNet152_Weights&#39;,
 &#39;ResNet18_Weights&#39;,
 &#39;ResNet34_Weights&#39;,
 &#39;ResNet50_Weights&#39;,
 &#39;ShuffleNetV2&#39;,
 &#39;ShuffleNet_V2_X0_5_Weights&#39;,
 &#39;ShuffleNet_V2_X1_0_Weights&#39;,
 &#39;ShuffleNet_V2_X1_5_Weights&#39;,
 &#39;ShuffleNet_V2_X2_0_Weights&#39;,
 &#39;SqueezeNet&#39;,
 &#39;SqueezeNet1_0_Weights&#39;,
 &#39;SqueezeNet1_1_Weights&#39;,
 &#39;SwinTransformer&#39;,
 &#39;Swin_B_Weights&#39;,
 &#39;Swin_S_Weights&#39;,
 &#39;Swin_T_Weights&#39;,
 &#39;VGG&#39;,
 &#39;VGG11_BN_Weights&#39;,
 &#39;VGG11_Weights&#39;,
 &#39;VGG13_BN_Weights&#39;,
 &#39;VGG13_Weights&#39;,
 &#39;VGG16_BN_Weights&#39;,
 &#39;VGG16_Weights&#39;,
 &#39;VGG19_BN_Weights&#39;,
 &#39;VGG19_Weights&#39;,
 &#39;ViT_B_16_Weights&#39;,
 &#39;ViT_B_32_Weights&#39;,
 &#39;ViT_H_14_Weights&#39;,
 &#39;ViT_L_16_Weights&#39;,
 &#39;ViT_L_32_Weights&#39;,
 &#39;VisionTransformer&#39;,
 &#39;Wide_ResNet101_2_Weights&#39;,
 &#39;Wide_ResNet50_2_Weights&#39;,
 &#39;_GoogLeNetOutputs&#39;,
 &#39;_InceptionOutputs&#39;,
 &#39;__builtins__&#39;,
 &#39;__cached__&#39;,
 &#39;__doc__&#39;,
 &#39;__file__&#39;,
 &#39;__loader__&#39;,
 &#39;__name__&#39;,
 &#39;__package__&#39;,
 &#39;__path__&#39;,
 &#39;__spec__&#39;,
 &#39;_api&#39;,
 &#39;_meta&#39;,
 &#39;_utils&#39;,
 &#39;alexnet&#39;,
 &#39;convnext&#39;,
 &#39;convnext_base&#39;,
 &#39;convnext_large&#39;,
 &#39;convnext_small&#39;,
 &#39;convnext_tiny&#39;,
 &#39;densenet&#39;,
 &#39;densenet121&#39;,
 &#39;densenet161&#39;,
 &#39;densenet169&#39;,
 &#39;densenet201&#39;,
 &#39;detection&#39;,
 &#39;efficientnet&#39;,
 &#39;efficientnet_b0&#39;,
 &#39;efficientnet_b1&#39;,
 &#39;efficientnet_b2&#39;,
 &#39;efficientnet_b3&#39;,
 &#39;efficientnet_b4&#39;,
 &#39;efficientnet_b5&#39;,
 &#39;efficientnet_b6&#39;,
 &#39;efficientnet_b7&#39;,
 &#39;efficientnet_v2_l&#39;,
 &#39;efficientnet_v2_m&#39;,
 &#39;efficientnet_v2_s&#39;,
 &#39;get_weight&#39;,
 &#39;googlenet&#39;,
 &#39;inception&#39;,
 &#39;inception_v3&#39;,
 &#39;mnasnet&#39;,
 &#39;mnasnet0_5&#39;,
 &#39;mnasnet0_75&#39;,
 &#39;mnasnet1_0&#39;,
 &#39;mnasnet1_3&#39;,
 &#39;mobilenet&#39;,
 &#39;mobilenet_v2&#39;,
 &#39;mobilenet_v3_large&#39;,
 &#39;mobilenet_v3_small&#39;,
 &#39;mobilenetv2&#39;,
 &#39;mobilenetv3&#39;,
 &#39;optical_flow&#39;,
 &#39;quantization&#39;,
 &#39;regnet&#39;,
 &#39;regnet_x_16gf&#39;,
 &#39;regnet_x_1_6gf&#39;,
 &#39;regnet_x_32gf&#39;,
 &#39;regnet_x_3_2gf&#39;,
 &#39;regnet_x_400mf&#39;,
 &#39;regnet_x_800mf&#39;,
 &#39;regnet_x_8gf&#39;,
 &#39;regnet_y_128gf&#39;,
 &#39;regnet_y_16gf&#39;,
 &#39;regnet_y_1_6gf&#39;,
 &#39;regnet_y_32gf&#39;,
 &#39;regnet_y_3_2gf&#39;,
 &#39;regnet_y_400mf&#39;,
 &#39;regnet_y_800mf&#39;,
 &#39;regnet_y_8gf&#39;,
 &#39;resnet&#39;,
 &#39;resnet101&#39;,
 &#39;resnet152&#39;,
 &#39;resnet18&#39;,
 &#39;resnet34&#39;,
 &#39;resnet50&#39;,
 &#39;resnext101_32x8d&#39;,
 &#39;resnext101_64x4d&#39;,
 &#39;resnext50_32x4d&#39;,
 &#39;segmentation&#39;,
 &#39;shufflenet_v2_x0_5&#39;,
 &#39;shufflenet_v2_x1_0&#39;,
 &#39;shufflenet_v2_x1_5&#39;,
 &#39;shufflenet_v2_x2_0&#39;,
 &#39;shufflenetv2&#39;,
 &#39;squeezenet&#39;,
 &#39;squeezenet1_0&#39;,
 &#39;squeezenet1_1&#39;,
 &#39;swin_b&#39;,
 &#39;swin_s&#39;,
 &#39;swin_t&#39;,
 &#39;swin_transformer&#39;,
 &#39;vgg&#39;,
 &#39;vgg11&#39;,
 &#39;vgg11_bn&#39;,
 &#39;vgg13&#39;,
 &#39;vgg13_bn&#39;,
 &#39;vgg16&#39;,
 &#39;vgg16_bn&#39;,
 &#39;vgg19&#39;,
 &#39;vgg19_bn&#39;,
 &#39;video&#39;,
 &#39;vision_transformer&#39;,
 &#39;vit_b_16&#39;,
 &#39;vit_b_32&#39;,
 &#39;vit_h_14&#39;,
 &#39;vit_l_16&#39;,
 &#39;vit_l_32&#39;,
 &#39;wide_resnet101_2&#39;,
 &#39;wide_resnet50_2&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Instantiate a 101-layer convolutional neural network. (it downloads the weights of resnet101 trained on the ImageNet dataset, with 1.2 million images and 1,000 categories)</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet101</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and will be removed in 0.15, please use &#39;weights&#39; instead.
  f&quot;The parameter &#39;{pretrained_param}&#39; is deprecated since 0.13 and will be removed in 0.15, &quot;
/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: &quot;https://download.pytorch.org/models/resnet101-63fe2227.pth&quot; to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>





 
 
<div></div>
<div class="output_subarea output_widget_view">


</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Architecture of resnet</span>
<span class="n">resnet</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (6): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (7): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (8): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (9): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (10): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (11): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (12): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (13): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (14): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (15): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (16): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (17): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (18): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (19): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (20): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (21): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (22): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Loading an image</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/DL_data/bobby.jpg&quot;</span><span class="p">)</span>
<span class="n">img</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_png output_subarea output_execute_result">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Preprocess the images: scale the input image to 256 &#215; 256, crop the image to 224 &#215; 224 around the center, transform it to a tensor, and normalize its RGB (red, green, blue) components to match what was presented to the network during training</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span><span class="mf">0.456</span><span class="p">,</span><span class="mf">0.406</span><span class="p">],</span>
        <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span><span class="mf">0.224</span><span class="p">,</span><span class="mf">0.225</span><span class="p">]</span>
    <span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Pass the image through our preprocessing pipeline</span>
<span class="n">img_t</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">batch_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">img_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Predict image class</span>
<span class="n">resnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span>
<span class="n">out</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-3.4803e+00, -1.6618e+00, -2.4515e+00, -3.2662e+00, -3.2466e+00,
         -1.3611e+00, -2.0465e+00, -2.5112e+00, -1.3043e+00, -2.8900e+00,
         -1.6862e+00, -1.3055e+00, -2.6129e+00, -2.9645e+00, -2.4300e+00,
         -2.8143e+00, -3.3019e+00, -7.9404e-01, -6.5183e-01, -1.2308e+00,
         -3.0193e+00, -3.9457e+00, -2.2675e+00, -1.0811e+00, -1.0232e+00,
         -1.0442e+00, -3.0918e+00, -2.4613e+00, -2.1964e+00, -3.2354e+00,
         -3.3013e+00, -1.8553e+00, -2.0921e+00, -2.1327e+00, -1.9102e+00,
         -3.2403e+00, -1.1396e+00, -1.0925e+00, -1.2186e+00, -9.3332e-01,
         -4.5093e-01, -1.5489e+00,  1.4161e+00,  1.0871e-01, -1.8442e+00,
         -1.4806e+00,  9.6227e-01, -9.9456e-01, -3.0060e+00, -2.7384e+00,
         -2.5798e+00, -2.0666e+00, -1.8022e+00, -1.9328e+00, -1.7726e+00,
         -1.3041e+00, -4.5848e-01, -2.0537e+00, -3.2804e+00, -5.0451e-01,
         -3.8174e-01, -1.1147e+00, -7.3998e-01, -1.4299e+00, -1.4883e+00,
         -2.1073e+00, -1.7373e+00, -4.0412e-01, -1.9374e+00, -1.4862e+00,
         -1.2102e+00, -1.3223e+00, -1.0832e+00,  7.9207e-02, -4.1344e-01,
         -2.7477e-01, -8.5398e-01,  6.0364e-01, -8.9197e-01,  1.4761e+00,
         -2.6427e+00, -3.6478e+00, -2.7066e-01, -1.2360e-01, -2.2445e+00,
         -2.3425e+00, -1.4430e+00,  2.5264e-01, -1.0588e+00, -2.8812e+00,
         -2.5145e+00, -2.2579e+00,  4.1647e-01, -1.3463e+00, -1.6449e-02,
         -2.8798e+00, -5.5658e-01, -1.3859e+00, -2.9352e+00, -1.8880e+00,
         -4.2244e+00, -2.9742e+00, -2.0298e+00, -2.3869e+00, -2.7324e+00,
         -3.9905e+00, -3.6113e+00, -5.4423e-01, -1.0291e+00, -1.8998e+00,
         -3.5611e+00, -1.5031e+00,  1.0660e+00, -7.1587e-01, -7.2612e-01,
         -2.2173e+00, -2.2616e+00, -5.9990e-01, -1.4349e+00, -2.5965e+00,
         -3.9844e+00, -9.4164e-01, -5.3676e-01, -8.4138e-01, -1.1660e+00,
         -7.3556e-01, -1.1300e+00, -2.1074e+00, -4.0037e+00, -3.7229e-01,
         -2.7179e+00, -2.9849e+00, -1.9127e+00, -1.8412e+00, -1.3001e+00,
         -2.2268e+00, -2.0247e+00, -3.1761e+00, -3.2964e+00, -2.7923e+00,
         -4.3191e-01, -3.7750e+00, -2.4832e+00, -2.6228e+00, -2.7499e+00,
         -2.6306e+00, -3.2714e+00, -4.3249e+00, -4.2451e+00, -3.6207e+00,
         -1.1967e+00,  2.3839e+00,  1.8833e+00,  2.2390e+00,  4.9467e+00,
          9.9434e-01,  2.9570e+00,  8.5852e-01,  2.2356e+00,  6.1872e+00,
          4.2074e+00,  4.6280e+00,  7.5066e+00,  4.3456e+00,  4.8873e+00,
          5.8086e+00,  4.0282e+00,  3.5778e+00,  9.5398e+00,  1.0959e+00,
          3.3065e+00,  1.9473e+00, -4.7347e-01,  1.4388e+00,  1.8860e+00,
          5.5149e+00,  5.6885e+00,  2.1434e+00,  2.5016e+00,  6.2614e-01,
          1.9095e+00,  1.4927e+00,  3.4522e+00,  4.0987e-01,  4.2790e+00,
          4.3379e+00,  1.2945e+00,  1.6308e+00,  1.1426e+00,  2.1246e+00,
          8.6190e-01,  3.0266e+00,  3.5030e+00,  2.7914e+00,  1.8812e+00,
          1.3916e-01,  2.0182e+00,  2.6938e+00,  1.0643e+00,  1.9063e+00,
          3.5028e+00,  2.2950e+00,  2.5388e+00,  1.3140e+00,  3.5698e+00,
          7.7051e+00,  4.3443e+00,  1.5674e+01,  1.2140e+01,  5.2050e+00,
          1.9331e+00,  5.4996e+00,  6.1745e+00,  7.5155e+00,  5.8567e+00,
          6.9794e+00,  5.6891e+00,  2.6934e+00,  5.3248e+00,  9.8436e+00,
          6.4168e+00,  2.4431e+00,  5.6031e+00,  3.4884e+00,  2.0732e+00,
          1.3375e+00,  2.5550e+00,  5.7791e+00,  7.5825e-01,  1.0360e+00,
          4.8250e+00,  5.9932e+00,  3.9907e+00, -1.7508e+00,  3.6606e+00,
          2.8820e+00,  2.8978e+00,  1.3059e+00,  4.2622e+00,  4.0880e+00,
          3.4181e+00,  2.3945e+00,  3.1604e-01,  8.7091e-01,  5.0895e+00,
         -7.0908e-01,  1.9885e+00,  2.8699e+00,  2.5281e+00,  1.9253e+00,
          6.5843e-01,  3.4956e+00, -5.6701e-01,  1.9219e+00,  5.0423e-01,
          2.3949e+00,  3.4628e+00,  5.1851e+00,  1.8182e+00,  3.9127e+00,
          4.3620e+00,  3.3723e-01, -4.6588e-01,  5.6958e+00,  3.7192e+00,
          2.4205e+00,  3.6402e+00,  3.3705e+00, -9.3733e-01, -2.0590e-01,
          1.3018e-01,  1.1554e+00, -4.0951e-02,  4.5523e+00, -1.8349e+00,
         -2.6543e+00, -1.6859e+00, -6.3751e-01, -1.5596e+00, -2.1529e+00,
         -1.0245e+00,  1.5312e+00,  7.6857e-01, -1.8030e+00,  6.9033e-01,
          9.1473e-01, -2.0907e+00, -2.1250e+00, -1.5808e+00, -4.7830e+00,
         -1.0396e+00, -9.7836e-01, -2.0528e+00,  1.9793e+00, -6.0107e-01,
         -2.4964e+00, -1.4914e+00, -3.2041e+00, -1.9067e+00, -5.9215e-01,
         -1.0509e+00,  1.3131e+00, -1.5027e+00, -2.0352e+00,  1.3009e+00,
          3.9806e-01, -3.5442e-01,  7.1537e-01, -3.0086e-01, -7.6254e-01,
         -5.4504e-01,  1.0533e+00,  1.1973e-01,  7.1265e-02,  1.3234e+00,
         -2.0051e+00, -1.7127e+00,  1.1415e+00, -4.3746e-01,  2.9573e-01,
         -1.4572e+00, -2.6234e+00, -2.5400e+00, -2.4128e-01, -2.3629e+00,
         -1.5560e+00, -2.5256e+00, -8.0395e-01,  1.5960e-01, -2.8029e+00,
         -1.8937e+00, -9.4297e-01, -3.8987e-01, -4.6732e-01, -7.8799e-01,
         -2.5103e+00, -1.8726e+00, -2.1138e+00, -5.5075e-01,  1.8876e-01,
         -2.0678e+00, -1.7942e+00, -2.4776e+00, -3.8874e+00, -4.4214e+00,
         -2.1606e+00, -1.9960e+00, -3.7195e+00, -1.8627e+00, -3.3882e+00,
         -2.0034e+00, -2.2823e+00, -8.3603e-01, -5.1364e-01, -2.9197e+00,
         -1.6728e+00, -2.5686e-01, -2.7734e+00, -1.7911e+00,  1.1283e-01,
         -2.1215e+00, -1.5402e+00, -1.2457e+00, -9.6399e-01, -2.4953e+00,
         -1.3973e+00, -3.8589e+00, -4.3189e+00, -1.5287e+00, -1.9420e+00,
         -3.0008e+00, -2.9597e+00, -4.8460e+00, -2.4737e+00, -1.4287e+00,
         -2.9093e+00, -1.2882e+00, -6.0873e-01, -2.8312e+00, -1.8754e+00,
         -2.3758e+00, -3.4176e+00, -2.5520e+00, -3.8709e+00, -4.4702e+00,
         -3.5587e+00, -9.4389e-01, -2.3503e+00, -2.0270e+00, -1.8470e+00,
         -3.2897e+00, -3.4712e+00, -2.8471e+00, -1.9893e+00, -3.7441e+00,
         -1.1865e+00, -2.8282e+00,  2.2839e-01, -1.3325e-01, -3.1261e-01,
          1.4785e-01,  1.7180e+00,  1.8871e+00, -3.1302e+00, -3.7345e+00,
         -2.6754e+00, -6.7742e-01, -8.4727e-01, -1.3179e+00,  4.7847e-01,
         -2.2918e+00,  4.7733e+00,  1.5100e+00, -1.5956e+00,  3.3496e+00,
          3.0611e+00,  1.5253e+00,  6.8673e-01,  1.2918e+00,  1.6387e+00,
          1.0631e-01,  1.3420e+00,  5.2414e-02,  1.0270e+00, -4.6863e-01,
         -1.3585e+00,  5.7504e-01,  2.8775e-01,  2.8255e+00,  2.1875e+00,
          1.8301e+00,  1.3566e+00,  1.0992e+00,  2.3172e+00,  6.4046e+00,
          1.8630e+00,  6.0024e-01, -1.4953e+00, -1.9144e+00, -2.6436e+00,
          1.5186e+00, -4.8838e-01, -1.0530e-01,  1.9803e+00, -1.7358e+00,
          3.7236e-01,  1.6658e+00,  7.8257e-01,  2.1721e+00, -1.4210e+00,
         -2.4550e+00,  4.6637e-01,  3.3418e+00, -2.8537e-01,  1.1941e-01,
          1.1450e+00, -1.3834e+00,  1.5737e+00, -2.1716e+00, -4.2427e-01,
         -1.4805e+00, -2.1745e+00,  2.7962e+00,  2.4990e+00,  1.9237e-01,
          4.7498e-01, -1.9682e+00, -1.6105e+00, -7.3869e-01, -1.1794e+00,
         -2.9532e-01, -1.4142e+00,  2.2398e+00, -4.3380e-01, -8.6286e-01,
          4.0300e-01, -1.4318e+00, -3.1364e-01,  3.4846e+00,  4.3202e-01,
          4.5058e-01, -1.1090e+00,  2.2513e-01, -2.6651e+00, -2.8278e+00,
         -6.5790e-01, -3.0889e-01,  8.2096e-01,  1.8005e-01, -4.2284e-01,
         -5.8541e-01, -2.7820e-01,  1.6590e+00,  8.7698e-02, -4.6728e-01,
          1.1241e+00,  2.2742e+00, -1.0448e+00,  9.4819e-01,  9.9525e-01,
         -2.5969e+00, -5.5236e-01,  2.1583e+00, -9.2215e-01,  4.7108e-02,
         -3.8016e-01,  1.5210e+00, -1.0433e+00,  1.9041e+00,  1.4741e+00,
         -4.3896e+00, -1.6206e-01, -1.5698e-01, -7.3738e-01,  1.8179e+00,
          3.3264e+00,  7.3696e-01, -7.6419e-01,  1.5898e+00,  1.9445e+00,
          1.2725e+00, -1.5624e+00,  2.2197e+00,  9.9570e-01, -6.3256e-01,
         -1.4160e+00,  1.6144e+00,  4.5531e-02,  9.0731e-01,  9.5069e-01,
          5.3562e-01,  4.4124e-01,  1.0358e+00,  6.5593e-01,  3.3626e+00,
         -1.0299e+00, -2.8939e+00, -7.0227e-01, -8.1103e-01,  7.0547e+00,
         -3.3097e+00,  1.3230e+00,  1.6968e+00,  3.7732e+00, -1.1723e+00,
          5.7985e-01, -1.8231e+00, -1.3483e+00,  4.1487e-01,  2.6429e+00,
          1.4418e+00,  7.9635e-01,  4.8719e+00,  1.5457e+00, -3.5932e+00,
         -2.2285e+00, -1.3850e+00, -8.9728e-01,  2.1657e+00,  2.0583e+00,
         -8.9567e-01, -1.7835e+00, -1.4516e+00,  1.0497e+00, -7.6032e-01,
         -1.4353e+00,  4.7010e-01,  8.7255e-01,  6.7030e-01, -1.1902e+00,
         -1.4175e+00, -8.4839e-01,  1.1901e+00, -1.8283e+00,  2.4775e+00,
          3.4005e-01, -1.7652e+00, -9.1973e-01,  2.9893e+00,  2.2373e+00,
         -8.1442e-01, -1.9843e+00,  9.2510e-01, -2.1452e+00,  1.8891e-02,
          2.5441e-01, -1.1333e-01, -6.2533e-01,  8.0225e-01,  4.0010e+00,
         -1.1935e+00,  2.6455e+00, -1.7860e+00,  7.5865e-01,  5.1593e-01,
          2.4376e-03, -7.6760e-01,  4.8149e-01,  1.3055e+00,  8.0364e-01,
         -6.1874e-01,  4.6970e-02,  2.6322e-01, -2.1400e+00, -1.3908e+00,
         -4.0182e-02, -4.2920e-01,  4.6767e-01,  1.3024e+00,  7.5817e-01,
          9.9857e-02, -1.0072e-01, -8.5241e-01,  8.6249e-01,  6.9517e-01,
          2.1217e+00,  7.1266e-01, -1.9782e-01,  2.3986e+00,  1.8734e+00,
          1.0993e+00,  1.0336e+00,  1.4353e+00, -4.9213e-02, -1.3295e-01,
         -1.7147e+00, -1.2590e+00, -1.3166e+00, -3.4476e+00,  5.9193e-01,
          1.0995e+00,  1.0987e-02, -3.7005e-01, -4.5369e-01, -4.2330e-01,
         -1.5137e+00,  2.7933e-01, -2.0776e-01,  3.2132e+00,  1.8063e+00,
         -1.5186e+00,  2.8835e+00, -7.4290e-01,  3.2128e-02, -7.0117e-02,
         -1.0103e+00,  1.1795e+00,  5.9283e-01,  1.2191e-01, -3.4571e+00,
          1.3048e+00,  3.9847e-01, -1.2731e+00, -1.2927e+00, -1.6408e+00,
          1.9229e+00,  4.1588e-02, -9.8906e-01,  6.7141e-01,  2.8807e+00,
          1.6977e+00,  2.2305e-01, -8.1440e-01, -2.0507e+00,  1.7015e+00,
         -2.0312e-01,  7.4630e-01,  1.5227e+00, -1.4377e+00, -1.1784e+00,
          5.1375e-01, -6.4234e-01,  3.8708e-02,  2.6664e+00, -1.6256e+00,
         -3.3457e+00,  2.1520e+00,  8.6618e-01,  1.3850e+00, -3.4029e-01,
          1.8385e-01,  1.4680e+00, -1.0961e+00,  1.8217e+00, -1.2748e+00,
         -2.1175e+00, -8.4857e-01, -5.3657e-01, -1.2562e+00,  1.1329e+00,
         -1.4191e+00, -7.6893e-01, -3.4133e-01,  2.1594e+00, -2.1836e-01,
         -1.8166e+00,  9.8038e-02,  1.7366e+00,  1.6465e-01,  7.7769e-01,
          4.7226e+00, -7.3754e-01, -1.6683e+00, -8.1360e-01, -1.4618e+00,
          3.4068e+00,  5.3348e-01, -3.1106e-01, -5.0764e-01,  3.0037e-01,
          1.8626e+00, -1.1852e+00, -2.0411e+00, -9.6967e-02, -7.1424e-01,
         -2.5433e+00, -3.4144e-02,  7.6702e-01, -1.7948e+00,  2.9510e-01,
         -1.0903e+00,  1.5320e+00,  2.8823e+00,  5.1182e-01, -7.6857e-01,
         -9.0145e-01, -1.7196e+00, -1.0044e+00,  9.1568e-01, -9.2978e-02,
         -2.3068e+00,  2.2911e+00,  9.5719e-01,  1.9917e+00, -1.6980e+00,
          2.6118e+00,  3.7953e+00,  7.1091e-01, -2.2801e-03, -1.0275e+00,
          2.1824e+00,  1.4127e+00,  4.7933e-01, -1.3249e+00, -9.0533e-01,
          5.8118e-01, -6.0400e-01,  5.1155e-01,  1.1511e+00,  9.5682e-01,
          2.7826e+00, -3.0976e+00,  3.5563e+00, -1.6181e-01, -4.6198e-02,
         -2.0769e+00, -1.4204e+00,  2.9824e+00, -4.8723e-01,  2.1408e-01,
         -1.3643e-01,  2.2942e+00,  3.4084e-01,  9.9796e-01, -1.1452e+00,
          3.3055e+00, -1.8049e+00,  3.2445e+00, -1.6493e-01,  1.3805e+00,
          6.5878e-01,  4.6122e-01, -7.8641e-01,  3.8983e-01,  1.9974e+00,
          4.0911e-01,  2.4162e+00, -1.9111e+00,  8.1044e-02,  2.2694e+00,
         -1.6680e+00, -7.0304e-01,  1.4299e+00,  1.4233e-02,  7.9249e-01,
          2.9637e+00, -9.4825e-01, -1.3366e+00,  2.6750e-01,  2.3589e+00,
          1.8983e+00,  1.8345e+00,  8.5127e-01,  4.2841e+00,  4.8082e-01,
         -1.4365e+00, -4.8286e-01,  3.0412e+00, -8.2025e-01,  3.3065e+00,
         -6.5939e-01, -2.6282e+00, -3.1888e+00, -2.9725e+00,  1.2156e+00,
          5.6016e+00,  3.0274e-01, -3.1681e+00,  2.5582e+00, -3.3199e-01,
          1.4820e-01,  2.3601e+00, -1.4552e+00,  3.3269e+00, -3.3744e+00,
         -6.4104e-01,  1.1680e+00, -2.6107e+00,  1.6885e+00, -1.5028e+00,
         -2.6845e+00, -3.6659e+00, -1.7394e+00,  1.1231e+00,  2.0104e+00,
         -1.4943e-01,  1.3057e+00,  1.2092e+00,  2.6647e+00, -1.7969e+00,
         -1.8525e+00,  1.5488e+00, -2.0861e+00, -2.3154e+00,  9.9215e-01,
         -3.7871e+00, -1.1176e+00,  9.0636e-01, -3.2947e-01, -3.4544e+00,
          2.0940e+00,  5.4372e-01,  6.0876e-01, -1.3066e-01,  7.9443e-01,
          7.9938e-01,  1.0587e+00, -1.8372e+00,  2.8466e-01, -1.1158e+00,
          8.0787e-01,  1.0870e+00,  8.9547e+00, -8.9419e-01, -9.3960e-01,
          1.0807e+00, -4.1462e-01, -1.7524e+00,  9.1855e-02,  1.8185e-01,
         -1.3849e+00,  8.8831e-01, -4.1253e-01, -7.7844e-01, -3.1265e+00,
         -3.8734e-01,  1.8115e-01, -2.2122e+00,  2.8848e+00,  4.5000e-01,
          1.4854e+00, -3.4138e+00,  1.4939e+00, -2.5266e+00, -2.9228e+00,
         -7.6507e-01,  2.8269e+00, -1.1918e+00, -6.2602e-01,  3.6187e+00,
          1.1527e+00,  1.1860e+00,  3.4149e+00,  9.2982e-01, -1.1376e+00,
          1.0391e+00,  1.8575e-01, -7.4427e-01, -2.9312e+00, -1.6815e-01,
          1.5624e+00, -4.5063e-01,  1.5997e+00,  1.0128e+00, -1.3146e+00,
         -1.8426e+00, -4.7445e-01,  5.8991e-01,  2.3850e+00,  5.2548e-01,
         -1.3760e+00, -2.3240e+00, -7.6861e-01,  1.2772e+00,  2.9579e+00,
         -2.7968e-01, -5.9378e-01, -2.4310e-02, -7.2352e-01, -5.9500e-02,
          2.7550e+00,  2.9499e-01, -1.1396e+00, -1.4785e+00, -4.3375e+00,
         -3.2104e-01, -3.2125e-01, -2.0806e+00,  3.7004e-01, -1.4368e+00,
         -6.1700e-01, -2.0341e+00, -8.6155e-01, -4.0387e-01, -3.2359e-01,
         -1.8287e+00, -1.7554e+00, -6.5640e-01,  6.7694e-01,  3.7156e+00,
          2.1207e+00,  4.0970e+00,  1.7257e+00,  8.5265e-01,  1.2722e+00,
          1.0563e+00,  1.3809e+00,  1.2871e+00, -7.5314e-01,  2.2593e+00,
          1.1952e-01, -7.3866e-01,  1.0060e+00,  8.5880e-01, -6.6744e-01,
         -3.2016e-01, -1.5605e+00,  2.0461e+00,  2.4740e+00,  2.2464e-01,
          7.4987e-01,  3.8843e-02, -1.7622e+00,  1.9534e+00,  4.5175e-01,
          1.2086e+00,  7.3219e-01, -1.0001e+00,  1.2820e-01, -3.7380e-01,
          9.6212e-02,  3.2060e+00,  6.5023e-01, -1.1252e-01,  8.9641e-01,
         -5.2855e-02, -1.1585e+00,  1.4922e-01,  3.7309e-01,  8.7084e-01,
         -1.9354e+00,  1.0733e-01, -1.5175e+00, -1.8582e+00, -3.8437e+00,
          1.8629e-01, -2.9438e+00,  5.4171e-01, -7.8057e-01, -2.6016e+00,
         -4.4594e+00,  5.5604e-01, -1.3140e+00, -3.8408e+00, -7.5988e-01,
         -5.7457e-01, -2.5448e+00,  2.3831e+00,  6.1368e-01,  4.8295e-01,
          2.8674e+00, -3.7442e+00,  1.5085e+00, -3.2500e+00, -2.4894e+00,
         -3.3541e-01,  1.2856e-01, -1.1355e+00,  3.3969e+00,  4.4584e+00]],
       grad_fn=&lt;AddmmBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Find out the label of the class that received the highest score: load a text file listing the labels in the same order they were presented to the network during training</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/DL_data/imagenet_classes.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Using the max function in PyTorch, which outputs the maximum value in a tensor as well as the indices where that maximum value occurred</span>
<span class="n">_</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">percentage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">index</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">percentage</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(tensor([207]), &#39;golden retriever&#39;, 96.29335021972656)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Sorts the values</span>
<span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">[(</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">percentage</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;golden retriever&#39;, 96.29335021972656),
 (&#39;Labrador retriever&#39;, 2.8081188201904297),
 (&#39;cocker spaniel, English cocker spaniel, cocker&#39;, 0.2826734781265259),
 (&#39;redbone&#39;, 0.2086300402879715),
 (&#39;tennis ball&#39;, 0.11621593683958054)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Load another image</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/DL_data/cat.jpg&quot;</span><span class="p">)</span>
<span class="n">img</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_text output_subarea">
<pre>Output hidden; open in https://colab.research.google.com to view.</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Process the image and predict the class</span>
<span class="n">img_t</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">batch_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">img_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">resnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span>
<span class="n">out</span> 

<span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">percentage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
<span class="p">[(</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">percentage</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[(&#39;tabby, tabby cat&#39;, 63.3458251953125),
 (&#39;Egyptian cat&#39;, 18.284372329711914),
 (&#39;tiger cat&#39;, 8.609886169433594),
 (&#39;space heater&#39;, 1.4025272130966187),
 (&#39;carton&#39;, 0.7487124800682068)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Part 2: A pretrained model that fakes it until it makes it<br/></h2>
<p>The CycleGAN network has been trained on a dataset of (unrelated) horse images and zebra images extracted from the ImageNet dataset.<br/></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">ResNetBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResNetBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_conv_block</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_conv_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="n">conv_block</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>

        <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>

        <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>

        <span class="n">conv_block</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_block</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">ResNetGenerator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_nc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ngf</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_blocks</span><span class="o">=</span><span class="mi">9</span><span class="p">):</span> 

        <span class="k">assert</span><span class="p">(</span><span class="n">n_blocks</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResNetGenerator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_nc</span> <span class="o">=</span> <span class="n">input_nc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nc</span> <span class="o">=</span> <span class="n">output_nc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ngf</span> <span class="o">=</span> <span class="n">ngf</span>

        <span class="n">model</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
                 <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_nc</span><span class="p">,</span> <span class="n">ngf</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                 <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">ngf</span><span class="p">),</span>
                 <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>

        <span class="n">n_downsampling</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_downsampling</span><span class="p">):</span>
            <span class="n">mult</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span>
            <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span><span class="p">,</span> <span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>

        <span class="n">mult</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">n_downsampling</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ResNetBlock</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span><span class="p">)]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_downsampling</span><span class="p">):</span>
            <span class="n">mult</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">n_downsampling</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
                                         <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                         <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ngf</span> <span class="o">*</span> <span class="n">mult</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">)]</span>

        <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
        <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">ngf</span><span class="p">,</span> <span class="n">output_nc</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>
        <span class="n">model</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span> 
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Create a generator</span>
<span class="n">netG</span> <span class="o">=</span> <span class="n">ResNetGenerator</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Load a generator model that had been pretrained on the horse2zebra dataset, whose training set contains two sets of 1068 and 1335 images of horses and zebras, respectively</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/DL_data/horse2zebra_0.4.0.pth&#39;</span>
<span class="n">model_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="n">netG</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;All keys matched successfully&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Put the network in evaluation mode</span>
<span class="n">netG</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>ResNetGenerator(
  (model): Sequential(
    (0): ReflectionPad2d((3, 3, 3, 3))
    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU(inplace=True)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (9): ReLU(inplace=True)
    (10): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (11): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (12): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (13): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (14): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (15): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (16): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (17): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (18): ResNetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (21): ReLU(inplace=True)
    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (24): ReLU(inplace=True)
    (25): ReflectionPad2d((3, 3, 3, 3))
    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))
    (27): Tanh()
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Read the horse image</span>
<span class="c1"># Loading an image</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/DL_data/horse.jpg&quot;</span><span class="p">)</span>
<span class="n">img</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_png output_subarea output_execute_result">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Define a few input transformations to make sure data enters the network with the right shape and size</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Preprocessing the image</span>
<span class="n">img_t</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">batch_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">img_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Convert the image</span>
<span class="n">batch_out</span> <span class="o">=</span> <span class="n">netG</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span>
<span class="n">out_t</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_out</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
<span class="n">out_img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()(</span><span class="n">out_t</span><span class="p">)</span>
<span class="n">out_img</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&#160;]:</div>




<div class="output_png output_subarea output_execute_result">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[&#160;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Generate a html file</span>
<span class="err">!</span><span class="n">jupyter</span> <span class="n">nbconvert</span> <span class="o">--</span><span class="n">to</span> <span class="n">html</span> <span class="s2">&quot;/content/drive/MyDrive/DL_lab/Lab 3_ Pretrained Networks.ipynb&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[NbConvertApp] Converting notebook /content/drive/MyDrive/DL_lab/Lab 3_ Pretrained Networks.ipynb to html
[NbConvertApp] Writing 3561500 bytes to /content/drive/MyDrive/DL_lab/Lab 3_ Pretrained Networks.html
</pre>
</div>
</div>

</div>
</div>

</div>
    </div>
  </div>


 





<script type="module" src="https://s.brightspace.com/lib/bsi/20.22.9-241/unbundled/mathjax.js"></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() {
					if (document.querySelector('math') || /\$\$|\\\(|\\\[|\\begin{|\\ref{|\\eqref{/.test(document.body.innerHTML)) {
						document.querySelectorAll('mspace[linebreak="newline"]').forEach(elm => {
							elm.setAttribute('style', 'display: block; height: 0.5rem;');
						});

						window.D2L.MathJax.loadMathJax({
							'outputScale': 1.3,
							'renderLatex': false
						});
					}
				});</script><script type="module" src="https://s.brightspace.com/lib/bsi/20.22.9-241/unbundled/prism.js"></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() {
					document.querySelectorAll('.d2l-code').forEach(code => {
						window.D2L.Prism.formatCodeElement(code);
					});
				});</script></body></html>